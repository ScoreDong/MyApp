{"cells":[{"metadata":{"id":"8695D1F8A6904D74AC3AD74DC3C83C94","mdEditEnable":false},"cell_type":"markdown","source":["# 神经网络解线性公式 y=ax+b\n","神经网络的 hello world"]},{"cell_type":"code","execution_count":1,"metadata":{"collapsed":false,"id":"35F2171D5F814FC18713D5A144FD2AC8","scrolled":false},"outputs":[],"source":["import numpy as np #科学计算模块"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":false,"id":"A228FF6569D8433B995BAC4C061DE663","scrolled":false},"outputs":[],"source":["# create data 创建最简单的神经网络模型 ，生成一组（x，y）用作训练数据\n","# 我们要提供一系列已经存在的(x,y) 组合，这个叫做训练集，我们先用代码生成 100 组训练集，先随机生成 5 组 x 的值，命名为 x_data，其中使用 np.random.random(]) 来生成随机数，令数据类型为浮点数 np.float32 以便于计算：\n","x_data = np.random.rand(100).astype(np.float32) #生成100个随机数列，数据类型是float32，tf中大多数都用的是float32\n","\n","#根据公式求得 y_data 的值\n","y_data = x_data*0.1 + 1.3 #0.1为权重，1.3为偏置"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"D11A0E8ABF254D8C840B43EC080DB2C7","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"x_data： [0.5803608  0.16169553 0.5495284  0.72427684 0.12302467] \n y_data [1.358036  1.3161695 1.3549528 1.3724276 1.3123025]\n","name":"stdout"}],"source":["# 结果如下，其中随机数每次执行会不一样(只展示前5个)：\n","print('x_data：',x_data[0:5],'\\n','y_data',y_data[0:5])"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"id":"5A27114EA7B24281B7FAFAAB60D1A7A5","scrolled":false},"outputs":[],"source":["import tensorflow as tf\n","### create tensorflow structure start ###设计预测模型\n","\n","Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))#用Variable初始化Weights权重变量-随机数列生成-1到1的1维数据，\n","\n","biases = tf.Variable(tf.zeros([1])) #偏置初始化为0，\n","\n","y = Weights*x_data + biases #所要预测的y，通过训练使得y逼近真实的y_data，优化得到的参数变量就即Weights和biases\n","\n","loss = tf.reduce_mean(tf.square(y-y_data)) #预测的y和实际的y_data的差别，即均方差\n","\n","optimizer = tf.train.GradientDescentOptimizer(0.5) #用tf的梯度下降优化器减少误差loss，提升参数的准确度，0.5为学习效率（一般小于1）)\n","\n","train = optimizer.minimize(loss) #训练以减少误差\n","\n"," \n","\n","init = tf.global_variables_initializer() #初始化tf结构图中的所有变量，这里是Weights和biases\n","\n","### create tensorflow structure end ###"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"id":"1088356C86E44D0C80D88ECBEA4BD51F","scrolled":false},"outputs":[],"source":["sess = tf.Session() #激活创建的结构图，Sesssion是神经网路的执行命令的对话控制\n","\n","sess.run(init) #激活init，也就是所有结构"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"5249D1E4214E42F68D18F8E1D47DEFC4","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"0 [0.05904108] [1.7806609] Tensor(\"Abs:0\", shape=(), dtype=float32)\n20 [0.03721605] [1.3326439] Tensor(\"Abs_1:0\", shape=(), dtype=float32)\n40 [0.0827848] [1.3089508] Tensor(\"Abs_2:0\", shape=(), dtype=float32)\n60 [0.09527966] [1.3024542] Tensor(\"Abs_3:0\", shape=(), dtype=float32)\n80 [0.09870566] [1.3006729] Tensor(\"Abs_4:0\", shape=(), dtype=float32)\n100 [0.09964504] [1.3001845] Tensor(\"Abs_5:0\", shape=(), dtype=float32)\n120 [0.09990264] [1.3000506] Tensor(\"Abs_6:0\", shape=(), dtype=float32)\n140 [0.09997334] [1.3000138] Tensor(\"Abs_7:0\", shape=(), dtype=float32)\n160 [0.09999269] [1.3000038] Tensor(\"Abs_8:0\", shape=(), dtype=float32)\n180 [0.09999799] [1.300001] Tensor(\"Abs_9:0\", shape=(), dtype=float32)\n200 [0.0999994] [1.3000002] Tensor(\"Abs_10:0\", shape=(), dtype=float32)\n","name":"stdout"}],"source":["for step in range(201):#让神经网络一步一步的训练 201步\n","    sess.run(train) # 开始训练\n","    if step % 20 == 0: #每间隔20步打印以下训练得到的变量值\n","        print(step, sess.run(Weights), sess.run(biases),abs(loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"C50C17A24B014CF182D6DA658EA74D4D"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":2}