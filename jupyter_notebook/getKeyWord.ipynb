{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何用Python提取中文关键词？\n",
    "本文一步步为你演示，如何用Python从中文文本中提取关键词。如果你需要对长文“观其大略”，不妨尝试一下。(单一文本关键词的提取方法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding=utf-8 -*-\n",
    "\n",
    "from jieba.analyse import *\n",
    "with open('../docs/HLS.TXT', encoding='utf-8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分别使用TF-idf、TextRank方式提取关键词和权重，并且依次显示出来。（如果你不做特殊指定的话，默认显示数量为20个关键词）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\admin\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.819 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "华莱士 0.5749792168986129\n",
      "汉堡 0.39108807238491805\n",
      "好吃 0.18820287275831382\n",
      "肯德基 0.1857926040998919\n",
      "麦当劳 0.11563439110617907\n",
      "真的 0.07408812614285894\n",
      "便宜 0.07396013976410017\n",
      "一次 0.06974735565839488\n",
      "炸鸡 0.06642716486849216\n",
      "味道 0.06475143603225725\n",
      "德克士 0.05765657252431995\n",
      "觉得 0.0565446127618267\n",
      "难吃 0.054525272124085755\n",
      "拉肚子 0.0510693509814628\n",
      "喜欢 0.03801040729809764\n",
      "但是 0.03759348759755\n",
      "鸡肉 0.03578067993249685\n",
      "还是 0.032300304126679884\n",
      "薯条 0.029981417712646376\n",
      "时候 0.029359099382223024\n",
      "确实 0.028899676051752837\n",
      "感觉 0.02845638481366961\n",
      "不是 0.0279917520942713\n",
      "一个 0.027916646274031703\n",
      "面包 0.02659056267602594\n",
      "卫生 0.02659000729389299\n",
      "口感 0.025721449335164834\n",
      "快餐 0.025142123629886506\n",
      "鸡腿 0.025111531198126463\n",
      "全鸡 0.02368986534532517\n"
     ]
    }
   ],
   "source": [
    "for keyword, weight in extract_tags(data, topK=30, withWeight=True):\n",
    "    print('%s %s' % (keyword, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汉堡 1.0\n",
      "好吃 0.5294748136633337\n",
      "觉得 0.25186444972026795\n",
      "时候 0.21537833756607694\n",
      "味道 0.20762097959298523\n",
      "没有 0.17378335548786464\n",
      "炸鸡 0.1609155055000764\n",
      "喜欢 0.12358307411887007\n",
      "感觉 0.12079093670899337\n",
      "东西 0.12014502083680705\n",
      "还有 0.10550502894660947\n",
      "知道 0.10235920045474588\n",
      "拉肚子 0.1006058781028921\n",
      "面包 0.09138705139249832\n",
      "问题 0.09066733696234519\n",
      "恶心 0.08928967877172363\n",
      "快餐 0.08803781981652214\n",
      "基本 0.08035067005749927\n",
      "成本 0.07856688156382047\n",
      "鸡肉 0.07711803935993211\n",
      "可能 0.07676839192907958\n",
      "口感 0.07329802648603322\n",
      "价格 0.07198656766876806\n",
      "放在 0.07175385881848129\n",
      "员工 0.06499075633227742\n",
      "不能 0.06493788561362425\n",
      "中国 0.06485200674230758\n",
      "牛肉 0.06396609476084783\n",
      "鸡块 0.06390791187555499\n",
      "外卖 0.06373689664495873\n"
     ]
    }
   ],
   "source": [
    "for keyword, weight in textrank(data, topK=30, withWeight=True):\n",
    "    print('%s %s' % (keyword, weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原理\n",
    "\n",
    "我们简要讲解一下，前文出现的2种不同关键词提取方式——TF-idf和TextRank的基本原理。\n",
    "\n",
    "为了不让大家感到枯燥，这里咱们就不使用数学公式了。后文我会给出相关的资料链接。如果你对细节感兴趣，欢迎按图索骥，查阅学习。\n",
    "\n",
    "先说TF-idf。\n",
    "\n",
    "它的全称是 Term Frequency - inverse document frequency。中间有个连字符，左右两侧各是一部分，共同结合起来，决定某个词的重要程度。\n",
    "\n",
    "第一部分，就是词频（Term Frequency），即某个词语出现的频率。\n",
    "\n",
    "我们常说“重要的事说三遍”。\n",
    "\n",
    "同样的道理，某个词语出现的次数多，也就说明这个词语重要性可能会很高。\n",
    "\n",
    "但是，这只是可能性，并不绝对。\n",
    "\n",
    "例如现代汉语中的许多虚词——“的，地，得”，古汉语中的许多句尾词“之、乎、者、也、兮”，这些词在文中可能出现许多次，但是它们显然不是关键词。\n",
    "\n",
    "这就是为什么我们在判断关键词的时候，需要第二部分（idf）配合。\n",
    "\n",
    "逆文档频率（inverse document frequency）首先计算某个词在各文档中出现的频率。假设一共有10篇文档，其中某个词A在其中10篇文章中都出先过，另一个词B只在其中3篇文中出现。请问哪一个词更关键？\n",
    "\n",
    "给你一分钟思考一下，然后继续读。\n",
    "\n",
    "公布答案时间到。\n",
    "\n",
    "答案是B更关键。\n",
    "\n",
    "A可能就是虚词，或者全部文档共享的主题词。而B只在3篇文档中出现，因此很有可能是个关键词。\n",
    "\n",
    "逆文档频率就是把这种文档频率取倒数。这样第一部分和第二部分都是越高越好。二者都高，就很有可能是关键词了。\n",
    "\n",
    "TF-idf讲完了，下面我们说说TextRank。\n",
    "\n",
    "相对于TF-idf，TextRank要显得更加复杂一些。它不是简单做加减乘除运算，而是基于图的计算。\n",
    "\n",
    "文章来源：https://zhuanlan.zhihu.com/p/31870596?group_id=923093802266013696"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
