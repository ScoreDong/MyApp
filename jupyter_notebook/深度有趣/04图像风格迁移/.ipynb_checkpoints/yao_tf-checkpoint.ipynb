{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用`TensorFlow`来实现图像风格迁移，主要用到深度学习中的卷积神经网络，即CNN。先用别人训练好的VGG模型来搞\n",
    "\n",
    "## 准备\n",
    "\n",
    "### 安装包\n",
    "\n",
    "`pip install numpy scipy tensorflow keras`\n",
    "再准备一些风格图片，和一张内容图片\n",
    "\n",
    "### python版本\n",
    "使用 python3.6，最新的 python3.7由于keras不支持，所以没办法使用\n",
    "\n",
    "## 原理\n",
    "\n",
    "为了将风格图的风格和内容图的内容进行融合，所生成的图片，在内容上应当尽可能接近内容图，在风格上应当尽可能接近风格图\n",
    "\n",
    "因此需要定义内容损失函数和风格损失函数，经过加权后作为总的损失函数\n",
    "\n",
    "### 实现步骤如下\n",
    "\n",
    "- 随机产生一张图片\n",
    "- 在每轮迭代中，根据总的损失函数，调整图片的像素值\n",
    "- 经过多轮迭代，得到优化后的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次运行使用的包版本为：keras.__version__ 2.2.4 np.__version__ 1.15.3 tf.__version__ 1.11.0 scipy.__version__ 1.1.0 Python 版本为 3.6.7 (v3.6.7:6ec5cf24b7, Oct 20 2018, 00:28:22) \n",
      "[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]\n"
     ]
    }
   ],
   "source": [
    "# 按惯例，导入一堆包\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications.vgg19 import VGG19,preprocess_input, decode_predictions\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os.path,sys,time\n",
    "# 输出靠谱日志必备\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "print(\"本次运行使用的包版本为：keras.__version__\",keras.__version__,\n",
    "\"np.__version__\",np.__version__,\"tf.__version__\",tf.__version__,\"scipy.__version__\",scipy.__version__,\"Python 版本为\",sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一些变量\n",
    "## 图片文件名、路径\n",
    "CONTENT_IMG , STYLE_IMG , OUTPUT_DIR = 'content.jpg', 'style1.jpg', 'neural_style_transfer_tensorflow/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "\tos.mkdir(OUTPUT_DIR)\n",
    "\n",
    "##  图像大小等\n",
    "IMAGE_W ,IMAGE_H,COLOR_C= 800,600,3\n",
    "NOISE_RATIO,BETA,ALPHA,VGG_MODEL,MEAN_VALUES  = 0.7,5,100,'imagenet-vgg-verydeep-19.mat',np.array([123.68, 116.779, 103.939]).reshape((1, 1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_vgg_model(path):\n",
    "    return model\n",
    "\n",
    "# 内容损失函数\n",
    "\n",
    "def content_loss_func(sess, model):\n",
    "\tdef _content_loss(p, x):\n",
    "\t\tN = p.shape[3]\n",
    "\t\tM = p.shape[1] * p.shape[2]\n",
    "\t\treturn (1 / (4 * N * M)) * tf.reduce_sum(tf.pow(x - p, 2))\n",
    "\treturn _content_loss(sess.run(model['conv4_2']), model['conv4_2'])\n",
    "\n",
    "# 风格损失函数\n",
    "\n",
    "STYLE_LAYERS = [('conv1_1', 0.5), ('conv2_1', 1.0), ('conv3_1', 1.5), ('conv4_1', 3.0), ('conv5_1', 4.0)]\n",
    "\n",
    "def style_loss_func(sess, model):\n",
    "\tdef _gram_matrix(F, N, M):\n",
    "\t\tFt = tf.reshape(F, (M, N))\n",
    "\t\treturn tf.matmul(tf.transpose(Ft), Ft)\n",
    "\n",
    "\tdef _style_loss(a, x):\n",
    "\t\tN = a.shape[3]\n",
    "\t\tM = a.shape[1] * a.shape[2]\n",
    "\t\tA = _gram_matrix(a, N, M)\n",
    "\t\tG = _gram_matrix(x, N, M)\n",
    "\t\treturn (1 / (4 * N ** 2 * M ** 2)) * tf.reduce_sum(tf.pow(G - A, 2))\n",
    "\treturn sum([_style_loss(sess.run(model[layer_name]), model[layer_name]) * w for layer_name, w in STYLE_LAYERS])\n",
    "\n",
    "# 随机产生一张初始图片\n",
    "\n",
    "def generate_noise_image(content_image, noise_ratio=NOISE_RATIO):\n",
    "\tnoise_image = np.random.uniform(-20, 20, (1, IMAGE_H, IMAGE_W, COLOR_C)).astype('float32')\n",
    "\tinput_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "\treturn input_image\n",
    "\n",
    "# 加载图片\n",
    "\n",
    "def load_image(path):\n",
    "\timage = scipy.misc.imread(path)\n",
    "\timage = scipy.misc.imresize(image, (IMAGE_H, IMAGE_W))\n",
    "\timage = np.reshape(image, ((1, ) + image.shape))\n",
    "\timage = image - MEAN_VALUES\n",
    "\treturn image\n",
    "\n",
    "# 保存图片\n",
    "\n",
    "def save_image(path, image):\n",
    "\timage = image + MEAN_VALUES\n",
    "\timage = image[0]\n",
    "\timage = np.clip(image, 0, 255).astype('uint8')\n",
    "\tscipy.misc.imsave(path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-24 11:12:12,997 - root - INFO - time-the_current_time()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "574717952/574710816 [==============================] - 1007s 2us/step\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"time-the_current_time()\")\n",
    "\n",
    "# 载入模型\n",
    "model = VGG19(weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:42: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Model' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a4d21a815f30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# sess.run(model['input'].assign(content_image))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mcontent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent_loss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# sess.run(model['input'].assign(style_image))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a2b692e6681a>\u001b[0m in \u001b[0;36mcontent_loss_func\u001b[0;34m(sess, model)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_content_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv4_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv4_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 风格损失函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Model' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "\tcontent_image = load_image(CONTENT_IMG)\n",
    "\tstyle_image = load_image(STYLE_IMG)\n",
    "\tmodel = load_vgg_model(VGG_MODEL)\n",
    "\n",
    "\tinput_image = generate_noise_image(content_image)\n",
    "\tsess.run(tf.global_variables_initializer())\n",
    "\n",
    "\t# sess.run(model['input'].assign(content_image))\n",
    "\tcontent_loss = content_loss_func(sess, model)\n",
    "\n",
    "\t# sess.run(model['input'].assign(style_image))\n",
    "\tstyle_loss = style_loss_func(sess, model)\n",
    "\n",
    "\ttotal_loss = BETA * content_loss + ALPHA * style_loss\n",
    "\toptimizer = tf.train.AdamOptimizer(2.0)\n",
    "\ttrain = optimizer.minimize(total_loss)\n",
    "\n",
    "\tsess.run(tf.global_variables_initializer())\n",
    "\t# sess.run(model['input'].assign(input_image))\n",
    "\n",
    "\tITERATIONS = 1330\n",
    "\tfor i in range(ITERATIONS):\n",
    "\t\tsess.run(train)\n",
    "\t\tif i-1 % 133 == 0:\n",
    "\t\t\toutput_image = sess.run(model['input'])\n",
    "\t\t\tlogging.info(\"time-the_current_time()\")\n",
    "\t\t\tlogging.info('Iteration %d' % i)\n",
    "\t\t\tprint('Cost: ', sess.run(total_loss))\n",
    "\t\t\tsave_image(os.path.join(OUTPUT_DIR, 'output_%d.jpg' % i), output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
