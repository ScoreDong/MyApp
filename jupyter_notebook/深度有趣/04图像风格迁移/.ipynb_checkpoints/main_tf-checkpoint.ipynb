{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用`TensorFlow`和`Keras`分别来实现图像风格迁移，主要用到深度学习中的卷积神经网络，即CNN\n",
    "\n",
    "## 准备\n",
    "\n",
    "### 安装包\n",
    "\n",
    "`pip install numpy scipy tensorflow keras`\n",
    "再准备一些风格图片，和一张内容图片\n",
    "\n",
    "### python版本\n",
    "使用 python3.6，最新的 python3.7由于keras不支持，所以没办法使用\n",
    "\n",
    "## 原理\n",
    "\n",
    "为了将风格图的风格和内容图的内容进行融合，所生成的图片，在内容上应当尽可能接近内容图，在风格上应当尽可能接近风格图\n",
    "\n",
    "因此需要定义内容损失函数和风格损失函数，经过加权后作为总的损失函数\n",
    "\n",
    "### 实现步骤如下\n",
    "\n",
    "- 随机产生一张图片\n",
    "- 在每轮迭代中，根据总的损失函数，调整图片的像素值\n",
    "- 经过多轮迭代，得到优化后的图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow实现\n",
    "\n",
    "## 加载库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2018-10-23 17:50:29\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "\n",
    "# 读取文件必备\n",
    "import os,sys,time\n",
    "\n",
    "# 输出靠谱日志必备\n",
    "import logging\n",
    "#是否开启debug？根据事件的轻重可分为以下几个级别：\n",
    "# DEBUG： 详细信息，通常仅在诊断问题时才受到关注。整数level=10\n",
    "# INFO： 确认程序按预期工作。整数level=20\n",
    "# WARNING：出现了异常，但是不影响正常工作.整数level=30\n",
    "# ERROR：由于某些原因，程序 不能执行某些功能。整数level=40\n",
    "# CRITICAL：严重的错误，导致程序不能运行。整数level=50\n",
    "# 默认的级别是WARNING,也就意味着只有级别大于等于的才会被看到，跟踪日志的方式可以是写入到文件中，也可以直接输出到控制台。\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def the_current_time():\n",
    "\tlogging.info(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(int(time.time()))))\n",
    "the_current_time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一些变量\n",
    "## 图片文件名、路径\n",
    "CONTENT_IMG , STYLE_IMG , OUTPUT_DIR = 'content.jpg', 'style5.jpg', 'neural_style_transfer_tensorflow/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "\tos.mkdir(OUTPUT_DIR)\n",
    "\n",
    "##  图像大小等\n",
    "IMAGE_W ,IMAGE_H,COLOR_C= 800,600,3\n",
    "NOISE_RATIO,BETA,ALPHA,VGG_MODEL,MEAN_VALUES  = 0.7,5,100,'imagenet-vgg-verydeep-19.mat',np.array([123.68, 116.779, 103.939]).reshape((1, 1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载VGG19模型\n",
    "\n",
    "def load_vgg_model(path):\n",
    "\t'''\n",
    "\tDetails of the VGG19 model:\n",
    "\t- 0 is conv1_1 (3, 3, 3, 64)\n",
    "\t- 1 is relu\n",
    "\t- 2 is conv1_2 (3, 3, 64, 64)\n",
    "\t- 3 is relu    \n",
    "\t- 4 is maxpool\n",
    "\t- 5 is conv2_1 (3, 3, 64, 128)\n",
    "\t- 6 is relu\n",
    "\t- 7 is conv2_2 (3, 3, 128, 128)\n",
    "\t- 8 is relu\n",
    "\t- 9 is maxpool\n",
    "\t- 10 is conv3_1 (3, 3, 128, 256)\n",
    "\t- 11 is relu\n",
    "\t- 12 is conv3_2 (3, 3, 256, 256)\n",
    "\t- 13 is relu\n",
    "\t- 14 is conv3_3 (3, 3, 256, 256)\n",
    "\t- 15 is relu\n",
    "\t- 16 is conv3_4 (3, 3, 256, 256)\n",
    "\t- 17 is relu\n",
    "\t- 18 is maxpool\n",
    "\t- 19 is conv4_1 (3, 3, 256, 512)\n",
    "\t- 20 is relu\n",
    "\t- 21 is conv4_2 (3, 3, 512, 512)\n",
    "\t- 22 is relu\n",
    "\t- 23 is conv4_3 (3, 3, 512, 512)\n",
    "\t- 24 is relu\n",
    "\t- 25 is conv4_4 (3, 3, 512, 512)\n",
    "\t- 26 is relu\n",
    "\t- 27 is maxpool\n",
    "\t- 28 is conv5_1 (3, 3, 512, 512)\n",
    "\t- 29 is relu\n",
    "\t- 30 is conv5_2 (3, 3, 512, 512)\n",
    "\t- 31 is relu\n",
    "\t- 32 is conv5_3 (3, 3, 512, 512)\n",
    "\t- 33 is relu\n",
    "\t- 34 is conv5_4 (3, 3, 512, 512)\n",
    "\t- 35 is relu\n",
    "\t- 36 is maxpool\n",
    "\t- 37 is fullyconnected (7, 7, 512, 4096)\n",
    "\t- 38 is relu\n",
    "\t- 39 is fullyconnected (1, 1, 4096, 4096)\n",
    "\t- 40 is relu\n",
    "\t- 41 is fullyconnected (1, 1, 4096, 1000)\n",
    "\t- 42 is softmax\n",
    "\t'''\n",
    "\tvgg = scipy.io.loadmat(path)\n",
    "\tvgg_layers = vgg['layers']\n",
    "\n",
    "\tdef _weights(layer, expected_layer_name):\n",
    "\t\tW = vgg_layers[0][layer][0][0][2][0][0]\n",
    "\t\tb = vgg_layers[0][layer][0][0][2][0][1]\n",
    "\t\tlayer_name = vgg_layers[0][layer][0][0][0][0]\n",
    "\t\tassert layer_name == expected_layer_name\n",
    "\t\treturn W, b\n",
    "\n",
    "\tdef _conv2d_relu(prev_layer, layer, layer_name):\n",
    "\t\tW, b = _weights(layer, layer_name)\n",
    "\t\tW = tf.constant(W)\n",
    "\t\tb = tf.constant(np.reshape(b, (b.size)))\n",
    "\t\treturn tf.nn.relu(tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b)\n",
    "\n",
    "\tdef _avgpool(prev_layer):\n",
    "\t\treturn tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\tgraph = {}\n",
    "\tgraph['input']    = tf.Variable(np.zeros((1, IMAGE_H, IMAGE_W, COLOR_C)), dtype='float32')\n",
    "\tgraph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
    "\tgraph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "\tgraph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "\tgraph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "\tgraph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "\tgraph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "\tgraph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "\tgraph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "\tgraph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "\tgraph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "\tgraph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "\tgraph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "\tgraph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "\tgraph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "\tgraph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "\tgraph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "\tgraph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "\tgraph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "\tgraph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "\tgraph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "\tgraph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "\treturn graph\n",
    "\n",
    "# 内容损失函数\n",
    "\n",
    "def content_loss_func(sess, model):\n",
    "\tdef _content_loss(p, x):\n",
    "\t\tN = p.shape[3]\n",
    "\t\tM = p.shape[1] * p.shape[2]\n",
    "\t\treturn (1 / (4 * N * M)) * tf.reduce_sum(tf.pow(x - p, 2))\n",
    "\treturn _content_loss(sess.run(model['conv4_2']), model['conv4_2'])\n",
    "\n",
    "# 风格损失函数\n",
    "\n",
    "STYLE_LAYERS = [('conv1_1', 0.5), ('conv2_1', 1.0), ('conv3_1', 1.5), ('conv4_1', 3.0), ('conv5_1', 4.0)]\n",
    "\n",
    "def style_loss_func(sess, model):\n",
    "\tdef _gram_matrix(F, N, M):\n",
    "\t\tFt = tf.reshape(F, (M, N))\n",
    "\t\treturn tf.matmul(tf.transpose(Ft), Ft)\n",
    "\n",
    "\tdef _style_loss(a, x):\n",
    "\t\tN = a.shape[3]\n",
    "\t\tM = a.shape[1] * a.shape[2]\n",
    "\t\tA = _gram_matrix(a, N, M)\n",
    "\t\tG = _gram_matrix(x, N, M)\n",
    "\t\treturn (1 / (4 * N ** 2 * M ** 2)) * tf.reduce_sum(tf.pow(G - A, 2))\n",
    "\treturn sum([_style_loss(sess.run(model[layer_name]), model[layer_name]) * w for layer_name, w in STYLE_LAYERS])\n",
    "\n",
    "# 随机产生一张初始图片\n",
    "\n",
    "def generate_noise_image(content_image, noise_ratio=NOISE_RATIO):\n",
    "\tnoise_image = np.random.uniform(-20, 20, (1, IMAGE_H, IMAGE_W, COLOR_C)).astype('float32')\n",
    "\tinput_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "\treturn input_image\n",
    "\n",
    "# 加载图片\n",
    "\n",
    "def load_image(path):\n",
    "\timage = scipy.misc.imread(path)\n",
    "\timage = scipy.misc.imresize(image, (IMAGE_H, IMAGE_W))\n",
    "\timage = np.reshape(image, ((1, ) + image.shape))\n",
    "\timage = image - MEAN_VALUES\n",
    "\treturn image\n",
    "\n",
    "# 保存图片\n",
    "\n",
    "def save_image(path, image):\n",
    "\timage = image + MEAN_VALUES\n",
    "\timage = image[0]\n",
    "\timage = np.clip(image, 0, 255).astype('uint8')\n",
    "\tscipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2018-10-23 17:50:35\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:130: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:131: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "INFO:root:2018-10-23 17:52:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Cost:  191332810000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:142: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "INFO:root:2018-10-23 18:37:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 133\n",
      "Cost:  1330977900.0\n"
     ]
    }
   ],
   "source": [
    "the_current_time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\tcontent_image = load_image(CONTENT_IMG)\n",
    "\tstyle_image = load_image(STYLE_IMG)\n",
    "\tmodel = load_vgg_model(VGG_MODEL)\n",
    "\n",
    "\tinput_image = generate_noise_image(content_image)\n",
    "\tsess.run(tf.global_variables_initializer())\n",
    "\n",
    "\tsess.run(model['input'].assign(content_image))\n",
    "\tcontent_loss = content_loss_func(sess, model)\n",
    "\n",
    "\tsess.run(model['input'].assign(style_image))\n",
    "\tstyle_loss = style_loss_func(sess, model)\n",
    "\n",
    "\ttotal_loss = BETA * content_loss + ALPHA * style_loss\n",
    "\toptimizer = tf.train.AdamOptimizer(2.0)\n",
    "\ttrain = optimizer.minimize(total_loss)\n",
    "\n",
    "\tsess.run(tf.global_variables_initializer())\n",
    "\tsess.run(model['input'].assign(input_image))\n",
    "\n",
    "\tITERATIONS = 2000\n",
    "\tfor i in range(ITERATIONS):\n",
    "\t\tsess.run(train)\n",
    "\t\tif i % 133 == 0:\n",
    "\t\t\toutput_image = sess.run(model['input'])\n",
    "\t\t\tthe_current_time()\n",
    "\t\t\tprint('Iteration %d' % i)\n",
    "\t\t\tprint('Cost: ', sess.run(total_loss))\n",
    "\n",
    "\t\t\tsave_image(os.path.join(OUTPUT_DIR, 'output_%d.jpg' % i), output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.__version__\n",
    "tensorflow.__version__\n",
    "numpy.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
